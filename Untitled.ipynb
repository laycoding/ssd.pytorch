{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8732, 21])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_conf.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules and functions\n",
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from data import coco as cfg\n",
    "from layers.box_utils import match, log_sum_exp, decode, nms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load intermidate variables\n",
    "conf_p = torch.load('./inter/conf_p.pt')\n",
    "conf_preds = torch.load('./inter/conf_preds.pt')\n",
    "effect_conf = torch.load('./inter/effect_conf.pt')\n",
    "effect_loc = torch.load('./inter/effect_loc.pt')\n",
    "conf_t = torch.load('./inter/conf_t.pt')\n",
    "loc_data = torch.load('./inter/loc_data.pt')\n",
    "conf_data = torch.load('./inter/conf_data.pt')\n",
    "priors = torch.load('./inter/priors.pt')\n",
    "targets = torch.load('./inter/targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = loc_data.size(0)\n",
    "priors = priors[:loc_data.size(1), :]\n",
    "# confused here, why stuck at loc_data size 1\n",
    "num_priors = (priors.size(0))\n",
    "# prior_data = priors.view(1, num_priors, 4)\n",
    "# print(prior_data.size())\n",
    "num_classes = 21\n",
    "conf_thresh = 0.1\n",
    "nms_thresh = 0.5\n",
    "top_k = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match priors (default boxes) and ground truth boxes\n",
    "loc_t = torch.Tensor(num, num_priors, 4)\n",
    "# [num, num_priors, 4]\n",
    "conf_t = torch.LongTensor(num, num_priors) \n",
    "# [num_priors] top class label for each prior\n",
    "for idx in range(num):\n",
    "    truths = targets[idx][:, :-1].data\n",
    "    labels = targets[idx][:, -1].data\n",
    "    defaults = priors.data\n",
    "    match(0.3, truths, defaults, cfg['variance'], labels,\n",
    "          loc_t, conf_t, idx)\n",
    "if True:\n",
    "    loc_t = loc_t.cuda()\n",
    "    conf_t = conf_t.cuda()\n",
    "# wrap targets\n",
    "# wrap targets\n",
    "loc_t = Variable(loc_t, requires_grad=False)\n",
    "conf_t = Variable(conf_t, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_preds = nn.Softmax(dim=-1)(conf_data.view(num, num_priors,\n",
    "                            num_classes))\n",
    "# 这里没有任何问题了，conf_preds加了softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_preds_trans = conf_preds.transpose(2,1)\n",
    "# [num, num_classes, num_priors]\n",
    "conf_p = torch.zeros(num, num_priors, num_classes).cuda()\n",
    "# [num, num_priors, num_classes]\n",
    "loc_p = torch.zeros(num, num_priors, 4).cuda()\n",
    "# Decode predictions into bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9910, 0.0002, 0.0001, 0.0007, 0.0002, 0.0009, 0.0002, 0.0006, 0.0003,\n",
       "        0.0005, 0.0003, 0.0002, 0.0003, 0.0002, 0.0002, 0.0023, 0.0005, 0.0006,\n",
       "        0.0002, 0.0002, 0.0003], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_preds[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重头戏开始，nms\n",
    "for i in range(num):        \n",
    "    decoded_boxes = decode(loc_data[i], priors, cfg['variance'])\n",
    "    # For each class, perform nms\n",
    "    conf_scores = conf_preds_trans[i].clone()\n",
    "    for cl in range(1, num_classes):\n",
    "        c_mask = conf_scores[cl].gt(conf_thresh)\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        if scores.size(0) == 0:\n",
    "            continue\n",
    "        # fliter low conf predictions\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "        boxes = Variable(decoded_boxes[l_mask].view(-1, 4), requires_grad=False)\n",
    "        # idx of highest scoring and non-overlapping boxes per class\n",
    "        # boxes [num_priors(has been flitered), 4] location preds for i'th image\n",
    "        ids, count = nms(boxes, scores, nms_thresh, top_k)\n",
    "        conf_p[i, c_mask.nonzero()[ids][:count], cl] = conf_preds[i, c_mask.nonzero()[ids][:count], cl] # [num, num_priors, num_classes]\n",
    "        loc_p[i, l_mask[:,0].nonzero()[ids][:count]] = loc_data[i, l_mask[:,0].nonzero()[ids][:count]] # [num, num_priors, 4]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8732, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_p[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8728]], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_mask[:,0].nonzero()[ids][:count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 9 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-d541681e59f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloc_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: index 9 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "loc_p[i, l_mask[:,0].nonzero()[:0][ids][:count]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l_mask[:,0] != l_mask[:,1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8732, 4])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_p.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_mask.nonzero().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8579],\n",
       "        [8609],\n",
       "        [8704],\n",
       "        [8705],\n",
       "        [8707],\n",
       "        [8708],\n",
       "        [8709],\n",
       "        [8710],\n",
       "        [8711],\n",
       "        [8728],\n",
       "        [8729],\n",
       "        [8730],\n",
       "        [8731]], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_mask[:,0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data[0][l_mask[:,0].nonzero()].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是一个难点，因为每个类下数量不一样，要选择出所有的，然后再扩展出去，然后这样每个anchor只能成为一类\n",
    "effect_conf = conf_p.sum(2) != 0\n",
    "effect_conf_idx = effect_conf.unsqueeze(2).expand_as(conf_p)\n",
    "effect_loc_idx = effect_conf.unsqueeze(2).expand_as(loc_t)\n",
    "num_effect = effect_loc.view(num, -1).sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "loss_c = F.cross_entropy(conf_p[effect_conf_idx].view(-1, num_classes), conf_t[effect_conf].view(-1), size_average=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1493.8805, device='cuda:0', grad_fn=<SmoothL1LossBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_l = F.smooth_l1_loss(loc_p[effect_loc_idx], loc_t[effect_loc_idx], size_average=False)\n",
    "loss_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13, device='cuda:0')\n",
      "torch.Size([8732, 4])\n"
     ]
    }
   ],
   "source": [
    "# cl为17th\n",
    "cl = 17\n",
    "c_mask = conf_scores[cl].gt(conf_thresh)\n",
    "print(c_mask.sum())\n",
    "scores = conf_scores[cl][c_mask]\n",
    "if scores.size(0) == 0:\n",
    "    print(\"0\")\n",
    "# fliter low conf predictions\n",
    "l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "boxes = Variable(decoded_boxes[l_mask].view(-1, 4), requires_grad=False)\n",
    "print(l_mask.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
